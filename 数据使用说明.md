# 📊 数据使用说明

## 🎯 数据文件说明

由于GitHub有25MB文件大小限制，我们将大文件分割成了小文件。现在你可以：

### 📁 分割后的文件

#### 上海主板数据 (18个文件)
- `上海主板_历史数据_2018至今_20250729_233546_副本2_part_01.csv` (19MB)
- `上海主板_历史数据_2018至今_20250729_233546_副本2_part_02.csv` (19MB)
- ... (共18个文件)

#### 深圳主板数据 (16个文件)
- `深圳主板_历史数据_2018至今_20250729_233546_副本_part_01.csv` (19MB)
- `深圳主板_历史数据_2018至今_20250729_233546_副本_part_02.csv` (19MB)
- ... (共16个文件)

## 🚀 使用方法

### 步骤1: 下载所有分割文件
从GitHub仓库下载所有 `*_part_*.csv` 文件

### 步骤2: 运行合并脚本
```bash
# 合并上海数据
python merge_上海主板_历史数据_2018至今_20250729_233546_副本2.py

# 合并深圳数据
python merge_深圳主板_历史数据_2018至今_20250729_233546_副本.py
```

### 步骤3: 验证合并结果
合并后会生成：
- `上海主板_历史数据_2018至今_20250729_233546_副本2_merged.csv` (343MB)
- `深圳主板_历史数据_2018至今_20250729_233546_副本_merged.csv` (308MB)

### 步骤4: 运行策略测试
```bash
# 运行AI精英策略
python V32_AI_Elite_Strategy.py

# 运行AI特征学习
python V31_AI_Feature_Learning.py
```

## 📋 数据格式

### CSV文件结构
```csv
ts_code,股票名称,所属板块,上市日期,行业,地区,trade_date,open,high,low,close,pre_close,change,pct_chg,vol,amount
600000.SH,浦发银行,上海主板,19991110,银行,上海,20250729,13.07,13.12,12.78,12.79,13.08,-0.29,-2.2171,789199.64,1017205.989
```

### 字段说明
- `ts_code`: 股票代码
- `股票名称`: 公司名称
- `trade_date`: 交易日期
- `open/high/low/close`: 开盘价/最高价/最低价/收盘价
- `vol/amount`: 成交量/成交额

## 🔧 技术细节

### 分割参数
- **最大文件大小**: 20MB (留5MB缓冲)
- **上海数据**: 2,757,271行 → 18个文件
- **深圳数据**: 2,480,029行 → 16个文件

### 合并验证
合并后的文件应该与原始文件完全一致：
- 行数相同
- 数据完整性
- 文件大小匹配

## ⚠️ 注意事项

1. **确保下载完整**: 所有分割文件都必须下载
2. **保持文件顺序**: 不要重命名或改变文件顺序
3. **检查文件大小**: 每个文件应该约19MB
4. **运行环境**: 需要pandas库支持

## 🆘 常见问题

### Q: 合并失败怎么办？
**解决方案**:
1. 检查是否下载了所有分割文件
2. 确认文件没有损坏
3. 重新下载缺失的文件

### Q: 文件太大无法下载？
**解决方案**:
1. 使用Git LFS: `git lfs pull`
2. 或者逐个下载分割文件

### Q: 策略运行失败？
**解决方案**:
1. 确认数据文件路径正确
2. 检查Python环境和依赖包
3. 查看错误日志

## 📞 获取帮助

如果遇到问题：
1. 查看GitHub Issues
2. 检查README.md文档
3. 运行测试脚本验证数据

---

**🎉 现在你可以轻松使用这些数据来测试你的量化交易策略了！** 