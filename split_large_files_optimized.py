#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆåˆ†å‰²å¤§æ–‡ä»¶è„šæœ¬
åˆ é™¤è‚¡ç¥¨åç§°åˆ—ï¼Œåªä¿ç•™è‚¡ç¥¨ä»£ç ï¼Œå¤§å¹…å‡å°‘æ–‡ä»¶å¤§å°
"""

import pandas as pd
import os
import math

def split_csv_file_optimized(input_file, output_prefix, max_size_mb=20):
    """
    ä¼˜åŒ–ç‰ˆåˆ†å‰²CSVæ–‡ä»¶ - åˆ é™¤è‚¡ç¥¨åç§°åˆ—
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
        max_size_mb: æ¯ä¸ªæ–‡ä»¶æœ€å¤§å¤§å°(MB)
    """
    print(f"å¼€å§‹ä¼˜åŒ–åˆ†å‰²æ–‡ä»¶: {input_file}")
    
    # è¯»å–æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(input_file) / (1024 * 1024)  # MB
    print(f"åŸå§‹æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
    
    # è¯»å–CSVæ–‡ä»¶
    print("æ­£åœ¨è¯»å–CSVæ–‡ä»¶...")
    df = pd.read_csv(input_file)
    total_rows = len(df)
    print(f"æ€»è¡Œæ•°: {total_rows:,}")
    
    # åˆ é™¤è‚¡ç¥¨åç§°åˆ—
    if 'è‚¡ç¥¨åç§°' in df.columns:
        df = df.drop(columns=['è‚¡ç¥¨åç§°'])
        print("å·²åˆ é™¤è‚¡ç¥¨åç§°åˆ—")
    
    # é‡æ–°è®¡ç®—æ–‡ä»¶å¤§å°
    temp_file = f"{output_prefix}_temp.csv"
    df.to_csv(temp_file, index=False)
    optimized_size = os.path.getsize(temp_file) / (1024 * 1024)  # MB
    print(f"ä¼˜åŒ–åæ–‡ä»¶å¤§å°: {optimized_size:.2f} MB")
    print(f"èŠ‚çœç©ºé—´: {file_size - optimized_size:.2f} MB ({((file_size - optimized_size) / file_size * 100):.1f}%)")
    
    # è®¡ç®—éœ€è¦åˆ†å‰²çš„æ–‡ä»¶æ•°é‡
    num_parts = math.ceil(optimized_size / max_size_mb)
    print(f"éœ€è¦åˆ†å‰²æˆ {num_parts} ä¸ªæ–‡ä»¶")
    
    rows_per_file = math.ceil(total_rows / num_parts)
    print(f"æ¯ä¸ªæ–‡ä»¶è¡Œæ•°: {rows_per_file:,}")
    
    # åˆ†å‰²æ–‡ä»¶
    for i in range(num_parts):
        start_idx = i * rows_per_file
        end_idx = min((i + 1) * rows_per_file, total_rows)
        
        # æå–æ•°æ®
        part_df = df.iloc[start_idx:end_idx]
        
        # ä¿å­˜æ–‡ä»¶
        output_file = f"{output_prefix}_part_{i+1:02d}.csv"
        part_df.to_csv(output_file, index=False)
        
        # è®¡ç®—æ–‡ä»¶å¤§å°
        part_size = os.path.getsize(output_file) / (1024 * 1024)
        print(f"å·²åˆ›å»º: {output_file} ({len(part_df):,} è¡Œ, {part_size:.2f} MB)")
    
    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_file)
    
    print(f"ä¼˜åŒ–åˆ†å‰²å®Œæˆï¼å…±åˆ›å»º {num_parts} ä¸ªæ–‡ä»¶")
    return num_parts

def create_merge_script_optimized(output_prefix, num_parts):
    """åˆ›å»ºä¼˜åŒ–ç‰ˆåˆå¹¶è„šæœ¬"""
    script_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆå¹¶ä¼˜åŒ–åˆ†å‰²çš„CSVæ–‡ä»¶ (å·²åˆ é™¤è‚¡ç¥¨åç§°åˆ—)
ä½¿ç”¨æ–¹æ³•: python merge_{output_prefix}.py
"""

import pandas as pd
import os

def merge_csv_files():
    """åˆå¹¶åˆ†å‰²çš„CSVæ–‡ä»¶"""
    print("å¼€å§‹åˆå¹¶ä¼˜åŒ–æ–‡ä»¶...")
    
    # è¯»å–æ‰€æœ‰åˆ†å‰²æ–‡ä»¶
    dfs = []
    for i in range(1, {num_parts + 1}):
        file_path = f"{output_prefix}_part_{{i:02d}}.csv"
        if os.path.exists(file_path):
            print(f"è¯»å–æ–‡ä»¶: {{file_path}}")
            df = pd.read_csv(file_path)
            dfs.append(df)
        else:
            print(f"è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {{file_path}}")
    
    if not dfs:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ†å‰²æ–‡ä»¶")
        return
    
    # åˆå¹¶æ•°æ®
    merged_df = pd.concat(dfs, ignore_index=True)
    print(f"åˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {{len(merged_df):,}}")
    
    # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
    output_file = f"{output_prefix}_merged.csv"
    merged_df.to_csv(output_file, index=False)
    print(f"å·²ä¿å­˜åˆå¹¶æ–‡ä»¶: {{output_file}}")
    
    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
    file_size = os.path.getsize(output_file) / (1024 * 1024)
    print(f"åˆå¹¶æ–‡ä»¶å¤§å°: {{file_size:.2f}} MB")
    print("æ³¨æ„: æ­¤æ–‡ä»¶å·²åˆ é™¤è‚¡ç¥¨åç§°åˆ—ï¼Œåªä¿ç•™è‚¡ç¥¨ä»£ç ")

if __name__ == "__main__":
    merge_csv_files()
'''
    
    script_file = f"merge_{output_prefix}.py"
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"å·²åˆ›å»ºä¼˜åŒ–åˆå¹¶è„šæœ¬: {script_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ä¼˜åŒ–ç‰ˆå¤§æ–‡ä»¶åˆ†å‰²å·¥å…· - åˆ é™¤è‚¡ç¥¨åç§°åˆ—")
    print("=" * 60)
    
    # åˆ†å‰²ä¸Šæµ·æ•°æ®
    print("\n1. ä¼˜åŒ–åˆ†å‰²ä¸Šæµ·æ•°æ®...")
    shanghai_parts = split_csv_file_optimized(
        "/Users/yamijin/Desktop/ä¸Šæµ·ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬2.csv",
        "ä¸Šæµ·ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬2_ä¼˜åŒ–ç‰ˆ",
        max_size_mb=20
    )
    create_merge_script_optimized("ä¸Šæµ·ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬2_ä¼˜åŒ–ç‰ˆ", shanghai_parts)
    
    # åˆ†å‰²æ·±åœ³æ•°æ®
    print("\n2. ä¼˜åŒ–åˆ†å‰²æ·±åœ³æ•°æ®...")
    shenzhen_parts = split_csv_file_optimized(
        "/Users/yamijin/Desktop/æ·±åœ³ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬.csv",
        "æ·±åœ³ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬_ä¼˜åŒ–ç‰ˆ",
        max_size_mb=20
    )
    create_merge_script_optimized("æ·±åœ³ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬_ä¼˜åŒ–ç‰ˆ", shenzhen_parts)
    
    print("\n" + "=" * 60)
    print("ä¼˜åŒ–åˆ†å‰²å®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ“‹ ä¼˜åŒ–æ•ˆæœ:")
    print(f"- ä¸Šæµ·æ•°æ®: åˆ†å‰²æˆ {shanghai_parts} ä¸ªæ–‡ä»¶")
    print(f"- æ·±åœ³æ•°æ®: åˆ†å‰²æˆ {shenzhen_parts} ä¸ªæ–‡ä»¶")
    print("- å·²åˆ é™¤è‚¡ç¥¨åç§°åˆ—ï¼Œå¤§å¹…å‡å°‘æ–‡ä»¶å¤§å°")
    print("\nğŸ“ éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶:")
    print("- ä¸Šæµ·ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬2_ä¼˜åŒ–ç‰ˆ_part_*.csv")
    print("- æ·±åœ³ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬_ä¼˜åŒ–ç‰ˆ_part_*.csv")
    print("- merge_*_ä¼˜åŒ–ç‰ˆ.py è„šæœ¬")

if __name__ == "__main__":
    main() 