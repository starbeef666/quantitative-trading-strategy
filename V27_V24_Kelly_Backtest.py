import pandas as pd
import numpy as np
import time
import warnings

warnings.filterwarnings('ignore')

# ==============================================================================
# å…¨å±€é…ç½® (V24å‡¯åˆ©ç‰ˆç­–ç•¥)
# ==============================================================================
DATA_PATH = 'ä¸Šæµ·ä¸»æ¿_å†å²æ•°æ®_2018è‡³ä»Š_20250729_233546_å‰¯æœ¬2.csv'
OUTPUT_CSV_PATH = 'V27_V24_Kelly_Trades.csv'

# V6 æ ¸å¿ƒå‚æ•°
V_BOTTOM_LOOKBACK = 20  # Vå‹åº•å›çœ‹å¤©æ•° (nâ‰¥20)
STOP_LOSS_PCT = 0.031   # å›ºå®šæ­¢æŸæ¯”ä¾‹
MAX_HOLDING_DAYS = 10   # æœ€å¤§æŒä»“å¤©æ•°

# V24å‡¯åˆ©æ€§èƒ½æ•°æ®è¡¨ (æ¥è‡ªæ‰“åˆ†å™¨)
KELLY_PERFORMANCE_LOOKUP = {
    0: {'W': 0.700, 'R': 5.66}, 1: {'W': 0.667, 'R': 3.94}, 2: {'W': 0.621, 'R': 3.66},
    3: {'W': 0.591, 'R': 2.78}, 4: {'W': 0.520, 'R': 2.74}, 5: {'W': 0.502, 'R': 2.63},
    6: {'W': 0.467, 'R': 2.43}, 7: {'W': 0.482, 'R': 2.66}, 8: {'W': 0.464, 'R': 2.74},
    9: {'W': 0.430, 'R': 2.57}, 10: {'W': 0.433, 'R': 2.62}, 11: {'W': 0.437, 'R': 2.69},
    12: {'W': 0.416, 'R': 3.18}, 13: {'W': 0.430, 'R': 2.76}, 14: {'W': 0.394, 'R': 2.55},
    15: {'W': 0.400, 'R': 2.68}, 16: {'W': 0.423, 'R': 2.70}, 17: {'W': 0.417, 'R': 2.77},
    18: {'W': 0.439, 'R': 3.18}, 19: {'W': 0.405, 'R': 2.54}, 20: {'W': 0.456, 'R': 2.78},
    21: {'W': 0.418, 'R': 2.83}, 22: {'W': 0.439, 'R': 2.71}, 23: {'W': 0.402, 'R': 2.75},
    24: {'W': 0.437, 'R': 2.55}, 25: {'W': 0.459, 'R': 2.67}, 26: {'W': 0.408, 'R': 2.76},
    27: {'W': 0.452, 'R': 2.43}, 28: {'W': 0.427, 'R': 2.78}, 29: {'W': 0.426, 'R': 2.53},
    30: {'W': 0.425, 'R': 2.82}, 31: {'W': 0.419, 'R': 2.54}, 32: {'W': 0.421, 'R': 2.78},
    33: {'W': 0.406, 'R': 2.35}, 35: {'W': 0.375, 'R': 2.63}, 36: {'W': 0.385, 'R': 2.40},
    37: {'W': 0.409, 'R': 2.66}, 38: {'W': 0.432, 'R': 2.23}, 39: {'W': 0.367, 'R': 2.63}
}

# ==============================================================================
# æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
# ==============================================================================
def calculate_rsi(series, period):
    """è®¡ç®—RSIæŒ‡æ ‡"""
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period, min_periods=1).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period, min_periods=1).mean()
    rs = gain / loss
    rs = rs.fillna(0)
    rs = rs.replace([np.inf, -np.inf], 999)
    return 100 - (100 / (1 + rs))

def load_and_preprocess_data(file_path):
    """åŠ è½½æ•°æ®å¹¶è®¡ç®—æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡"""
    print(f"å¼€å§‹åŠ è½½æ•°æ®...")
    start_time = time.time()
    try:
        df = pd.read_csv(file_path)
        print(f"æˆåŠŸåŠ è½½ {len(df):,} æ¡æ•°æ®è®°å½•")
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼")
        return None

    # æ ‡å‡†åŒ–åˆ—å
    df.rename(columns={
        'ts_code': 'ä»£ç ', 'trade_date': 'æ—¥æœŸ', 'open': 'å¼€ç›˜',
        'high': 'æœ€é«˜', 'low': 'æœ€ä½', 'close': 'æ”¶ç›˜',
        'vol': 'æˆäº¤é‡', 'amount': 'æˆäº¤é¢'
    }, inplace=True)
    
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y%m%d')
    df.sort_values(by=['ä»£ç ', 'æ—¥æœŸ'], inplace=True)
    
    print("â³ æ­£åœ¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
    grouped = df.groupby('ä»£ç ')
    
    # è®¡ç®—æ‰€æœ‰V24éœ€è¦çš„æŠ€æœ¯æŒ‡æ ‡
    df['rsi_14'] = grouped['æ”¶ç›˜'].transform(lambda x: calculate_rsi(x, 14))
    df['rsi_30'] = grouped['æ”¶ç›˜'].transform(lambda x: calculate_rsi(x, 30))
    
    # ATRè®¡ç®— (ä¿®å¤ç‰ˆ)
    df['high_low_diff'] = df['æœ€é«˜'] - df['æœ€ä½']
    df['atr'] = grouped['high_low_diff'].transform(lambda x: x.rolling(14, min_periods=1).mean())
    df['atr_ratio'] = df['atr'] / df['æ”¶ç›˜']
    df.drop('high_low_diff', axis=1, inplace=True)
    
    # ç§»åŠ¨å¹³å‡çº¿
    df['ma5'] = grouped['æ”¶ç›˜'].transform(lambda x: x.rolling(5, min_periods=1).mean())
    df['ma10'] = grouped['æ”¶ç›˜'].transform(lambda x: x.rolling(10, min_periods=1).mean())
    df['avg_vol_20'] = grouped['æˆäº¤é‡'].transform(lambda x: x.rolling(20, min_periods=1).mean())
    
    # æˆäº¤é¢å¤„ç†
    if 'æˆäº¤é¢' in df.columns:
        df['avg_amount_20'] = grouped['æˆäº¤é¢'].transform(lambda x: x.rolling(20, min_periods=1).mean())
    else:
        df['avg_amount_20'] = df['avg_vol_20'] * df['æ”¶ç›˜']
    
    print(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f} ç§’")
    return df

# ==============================================================================
# V6æ ¸å¿ƒä¿¡å·æ£€æµ‹
# ==============================================================================
def find_v6_base_signals(all_data):
    """å¯»æ‰¾æ‰€æœ‰ç¬¦åˆV6.0æ ¸å¿ƒå…¥åœºæ¡ä»¶çš„äº¤æ˜“ä¿¡å·"""
    print("å¼€å§‹å¯»æ‰¾V6.0æ ¸å¿ƒä¿¡å·...")
    start_time = time.time()
    
    signals = []
    grouped = all_data.groupby('ä»£ç ')
    
    for code, stock_data in grouped:
        if len(stock_data) < V_BOTTOM_LOOKBACK + 5:
            continue
            
        df = stock_data.copy().reset_index(drop=True)
        closes = df['æ”¶ç›˜'].values
        
        for i in range(V_BOTTOM_LOOKBACK + 4, len(closes)):
            # æ¡ä»¶1: è¿ç»­4å¤©æ”¶ç›˜ä»·ä¸å‡ Aâ‰¤Bâ‰¤Câ‰¤D
            if not (closes[i-3] <= closes[i-2] <= closes[i-1] <= closes[i]):
                continue
                
            # æ¡ä»¶2: Vå‹åº• - ç¬¬0å¤©(i-4)æ˜¯è¿‡å»nå¤©æœ€ä½ç‚¹
            day0_idx = i - 4
            window_start = max(0, day0_idx - V_BOTTOM_LOOKBACK + 1)
            window_closes = closes[window_start:day0_idx + 1]
            
            if closes[day0_idx] != min(window_closes):
                continue
                
            # è®°å½•ä¿¡å·å’Œå®Œæ•´çš„è‚¡ç¥¨æ•°æ®
            signals.append({
                'æ—¥æœŸ': df.iloc[i]['æ—¥æœŸ'],
                'ä»£ç ': code,
                'ä¹°å…¥ä»·æ ¼': closes[i],
                'æ•°æ®ç´¢å¼•': i,
                'è‚¡ç¥¨æ•°æ®': df
            })
            
    print(f"V6ä¿¡å·å¯»æ‰¾å®Œæˆï¼Œå…±æ‰¾åˆ° {len(signals)} ä¸ªï¼Œè€—æ—¶: {time.time() - start_time:.2f} ç§’")
    return signals

# ==============================================================================
# V24ç‰¹å¾æå–
# ==============================================================================
def extract_v24_features(stock_data, i):
    """æå–V24å‡¯åˆ©æ‰“åˆ†å™¨ä½¿ç”¨çš„ç‰¹å¾"""
    try:
        row = stock_data.iloc[i]
        prev_row = stock_data.iloc[i-1] if i > 0 else row
        
        open_p, close_p, high_p, low_p = row['å¼€ç›˜'], row['æ”¶ç›˜'], row['æœ€é«˜'], row['æœ€ä½']
        entity = abs(close_p - open_p)
        full_range = high_p - low_p if high_p > low_p else 1e-6
        
        features = {
            'rsi_14': row['rsi_14'],
            'rsi_30': row['rsi_30'],
            'atr_ratio': row['atr_ratio'],
            'body_ratio': entity / full_range,
            'upper_shadow_ratio': (high_p - max(open_p, close_p)) / (entity if entity > 0 else 1e-6),
            'lower_shadow_ratio': (min(open_p, close_p) - low_p) / (entity if entity > 0 else 1e-6),
            'vol_amp': row['æˆäº¤é‡'] / row['avg_vol_20'] if row['avg_vol_20'] > 0 else 1,
            'amount_amp': row['æˆäº¤é¢'] / row['avg_amount_20'] if row['avg_amount_20'] > 0 else 1,
            'ma5_above_ma10': 1 if row['ma5'] > row['ma10'] else 0,
            'close_above_ma5': 1 if close_p > row['ma5'] else 0,
            'gap_open': (open_p - prev_row['æ”¶ç›˜']) / prev_row['æ”¶ç›˜'] if i > 0 and prev_row['æ”¶ç›˜'] > 0 else 0
        }
        
        # è¿ç»­ä¸Šæ¶¨å¤©æ•°
        consecutive_up = 0
        for k in range(i, max(i-10, 0), -1):
            if k > 0 and stock_data.iloc[k]['æ”¶ç›˜'] >= stock_data.iloc[k-1]['æ”¶ç›˜']:
                consecutive_up += 1
            else:
                break
        features['consecutive_up_days'] = consecutive_up
        
        # åº•éƒ¨æ·±åº¦
        if i >= 20:
            min_low = stock_data.iloc[max(0, i-20):i]['æœ€ä½'].min()
            features['bottom_depth'] = (close_p - min_low) / min_low if min_low > 0 else 0
        else:
            features['bottom_depth'] = 0
            
        return features
    except:
        return None

# ==============================================================================
# V24 AIè¯„åˆ†ä¸å‡¯åˆ©ç­›é€‰
# ==============================================================================
def v24_ai_scoring(signals_df):
    """V24 AIè¯„åˆ†ç®—æ³•"""
    if signals_df.empty:
        return signals_df
    
    print("ğŸ§  æ­£åœ¨è¿›è¡ŒV24 AIè¯„åˆ†...")
    
    # V24ç‰¹å¾æƒé‡ (æ¥è‡ªæ‰“åˆ†å™¨ä»£ç )
    feature_weights = {
        'rsi_30': 0.25,
        'bottom_depth': 0.25,
        'atr_ratio': 0.15,
        'rsi_14': 0.10,
        'gap_open': 0.10,
        'vol_amp': 0.08,
        'lower_shadow_ratio': 0.07
    }
    
    scores = np.zeros(len(signals_df))
    
    for feature, weight in feature_weights.items():
        if feature in signals_df.columns:
            values = signals_df[feature].fillna(0)
            if values.std() > 0:
                normalized = (values - values.min()) / (values.max() - values.min())
                scores += normalized * weight
    
    signals_df['AIè¯„åˆ†'] = scores
    return signals_df.sort_values('AIè¯„åˆ†', ascending=False)

def assign_kelly_position(signals_df):
    """V24å‡¯åˆ©ä»“ä½åˆ†é…"""
    if signals_df.empty:
        return signals_df
    
    print("ğŸ“Š æ­£åœ¨è¿›è¡Œå‡¯åˆ©ä»“ä½åˆ†é…...")
    
    # è®¡ç®—æ’åç™¾åˆ†ä½
    signals_df['æ’åç™¾åˆ†ä½'] = signals_df['AIè¯„åˆ†'].rank(pct=True) * 100
    signals_df['æ€§èƒ½æ¡£ä½'] = np.floor(signals_df['æ’åç™¾åˆ†ä½']).astype(int)
    
    # åªä¿ç•™æœ‰æ•ˆæ¡£ä½çš„ä¿¡å·
    eligible = signals_df[signals_df['æ€§èƒ½æ¡£ä½'].isin(KELLY_PERFORMANCE_LOOKUP.keys())].copy()
    
    if eligible.empty:
        print("è­¦å‘Šï¼šæ²¡æœ‰ä¿¡å·è½åœ¨æœ‰æ•ˆçš„å‡¯åˆ©æ¡£ä½ä¸­")
        return pd.DataFrame()
    
    # æ˜ å°„èƒœç‡å’Œç›ˆäºæ¯”
    eligible['W'] = eligible['æ€§èƒ½æ¡£ä½'].map(lambda x: KELLY_PERFORMANCE_LOOKUP[x]['W'])
    eligible['R'] = eligible['æ€§èƒ½æ¡£ä½'].map(lambda x: KELLY_PERFORMANCE_LOOKUP[x]['R'])
    
    # è®¡ç®—å‡¯åˆ©ä»“ä½
    W, R = eligible['W'], eligible['R']
    kelly_pct = np.maximum(0, (W - (1 - W) / R) * 100)
    
    eligible['æ¿€è¿›ä»“ä½'] = kelly_pct
    eligible['ä¸­ç«‹ä»“ä½'] = kelly_pct / 2
    eligible['ä¿å®ˆä»“ä½'] = kelly_pct / 4
    
    print(f"å‡¯åˆ©ç­›é€‰å®Œæˆï¼šä» {len(signals_df)} ä¸ªä¿¡å·ä¸­ç­›é€‰å‡º {len(eligible)} ä¸ªæœ‰æ•ˆä¿¡å·")
    
    return eligible.sort_values('æ’åç™¾åˆ†ä½', ascending=False)

# ==============================================================================
# V24å‡¯åˆ©å›æµ‹é€»è¾‘
# ==============================================================================
def run_v24_kelly_backtest(all_data, kelly_signals, position_type='ä¸­ç«‹ä»“ä½'):
    """æ‰§è¡ŒV24å‡¯åˆ©ç­–ç•¥å›æµ‹"""
    print(f"å¼€å§‹æ‰§è¡ŒV24å‡¯åˆ©ç­–ç•¥å›æµ‹ (ä½¿ç”¨{position_type})...")
    start_time = time.time()
    
    trades = []
    active_trades = {}
    
    if kelly_signals.empty:
        return pd.DataFrame()
        
    unique_dates = sorted(kelly_signals['æ—¥æœŸ'].unique())
    stock_groups = all_data.groupby('ä»£ç ')

    for current_date in unique_dates:
        # æ¸…ç†å·²åˆ°æœŸçš„æŒä»“
        ended_stocks = [code for code, end_date in active_trades.items() if current_date >= end_date]
        for code in ended_stocks:
            del active_trades[code]
        
        daily_signals = kelly_signals[kelly_signals['æ—¥æœŸ'] == current_date]
        
        for _, signal in daily_signals.iterrows():
            stock_code = signal['ä»£ç ']
            
            if stock_code in active_trades:
                continue
            
            entry_price = signal['ä¹°å…¥ä»·æ ¼']
            buy_date = signal['æ—¥æœŸ']
            position_size = signal[position_type] / 100  # è½¬æ¢ä¸ºå°æ•°
            
            # è·å–è¯¥è‚¡ç¥¨çš„æœªæ¥æ•°æ®
            if stock_code not in stock_groups.groups:
                continue
                
            stock_data = stock_groups.get_group(stock_code)
            future_data = stock_data[stock_data['æ—¥æœŸ'] > buy_date].head(MAX_HOLDING_DAYS + 2)
            
            if len(future_data) < 1:
                continue

            # V6äº¤æ˜“ç®¡ç† + V24å‡¯åˆ©ä»“ä½
            remaining_shares = position_size
            total_pnl = 0.0
            prev_close = entry_price
            is_first_drop = True
            
            stop_loss_price = entry_price * (1 - STOP_LOSS_PCT)
            
            sell_date = None
            exit_reason = f"æŒæœ‰{MAX_HOLDING_DAYS}å¤©åˆ°æœŸ"

            for i in range(min(len(future_data), MAX_HOLDING_DAYS)):
                current_row = future_data.iloc[i]
                current_close = current_row['æ”¶ç›˜']
                
                # 1. ç¡¬æ­¢æŸæ£€æŸ¥
                if current_close < stop_loss_price:
                    sell_date = current_row['æ—¥æœŸ']
                    remaining_pnl = remaining_shares * (stop_loss_price / entry_price - 1)
                    total_pnl += remaining_pnl
                    remaining_shares = 0
                    exit_reason = "ç¡¬æ­¢æŸ"
                    break

                # 2. åˆ†çº§å‡ä»“ä¸è±å…æœŸ
                if current_close < prev_close:
                    if is_first_drop:
                        is_first_drop = False
                    else:
                        drop_pct = (prev_close - current_close) / prev_close
                        sell_shares = 0
                        if 0 < drop_pct <= 0.02:
                            sell_shares = remaining_shares * 0.10
                        elif drop_pct > 0.02:
                            sell_shares = remaining_shares * 0.20
                        
                        if sell_shares > 0:
                            sell_pnl = sell_shares * (current_close / entry_price - 1)
                            total_pnl += sell_pnl
                            remaining_shares -= sell_shares
                
                prev_close = current_close

            # 3. æœ€ç»ˆé€€å‡ºå¤„ç†
            if sell_date is None:
                exit_day_index = min(MAX_HOLDING_DAYS - 1, len(future_data) - 1)
                sell_date = future_data.iloc[exit_day_index]['æ—¥æœŸ']
                exit_price = future_data.iloc[exit_day_index]['æ”¶ç›˜']
                if remaining_shares > 0:
                    remaining_pnl = remaining_shares * (exit_price / entry_price - 1)
                    total_pnl += remaining_pnl
            
            trades.append({
                'ä»£ç ': stock_code,
                'ä¹°å…¥æ—¥æœŸ': buy_date,
                'ä¹°å…¥ä»·æ ¼': entry_price,
                'å–å‡ºæ—¥æœŸ': sell_date,
                'æ€»æ”¶ç›Šç‡': total_pnl,
                'é€€å‡ºåŸå› ': exit_reason,
                'AIè¯„åˆ†': signal['AIè¯„åˆ†'],
                'æ’åç™¾åˆ†ä½': signal['æ’åç™¾åˆ†ä½'],
                'å‡¯åˆ©ä»“ä½': signal[position_type],
                'èƒœç‡é¢„æœŸ': signal['W'],
                'ç›ˆäºæ¯”é¢„æœŸ': signal['R']
            })
            
            active_trades[stock_code] = sell_date

    print(f"V24å‡¯åˆ©å›æµ‹å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f} ç§’")
    return pd.DataFrame(trades)

# ==============================================================================
# æ€§èƒ½åˆ†æ
# ==============================================================================
def analyze_v24_performance(trades_df, position_type='ä¸­ç«‹ä»“ä½'):
    if trades_df.empty:
        print("V24å‡¯åˆ©å›æµ‹æœªäº§ç”Ÿä»»ä½•äº¤æ˜“ã€‚")
        return

    total_trades = len(trades_df)
    win_trades = trades_df[trades_df['æ€»æ”¶ç›Šç‡'] > 0]
    loss_trades = trades_df[trades_df['æ€»æ”¶ç›Šç‡'] <= 0]
    
    win_rate = len(win_trades) / total_trades if total_trades > 0 else 0
    avg_return = trades_df['æ€»æ”¶ç›Šç‡'].mean()
    avg_win = win_trades['æ€»æ”¶ç›Šç‡'].mean() if not win_trades.empty else 0
    avg_loss = loss_trades['æ€»æ”¶ç›Šç‡'].mean() if not loss_trades.empty else 0
    
    # å‡¯åˆ©é¢„æœŸ vs å®é™…
    expected_win_rate = trades_df['èƒœç‡é¢„æœŸ'].mean()
    expected_profit_loss_ratio = trades_df['ç›ˆäºæ¯”é¢„æœŸ'].mean()
    actual_profit_loss_ratio = -avg_win / avg_loss if avg_loss != 0 else 0
    
    print("\n" + "="*70)
    print(f"V24.0 å‡¯åˆ©ç­–ç•¥æ€§èƒ½åˆ†æ ({position_type})")
    print("="*70)
    print(f"æ€»äº¤æ˜“æ¬¡æ•°: {total_trades:,.0f}")
    print(f"èƒœç‡: {win_rate:.2%}")
    print(f"æœŸæœ›æ”¶ç›Š (å¹³å‡æ€»æ”¶ç›Šç‡): {avg_return:.4%}")
    print(f"å¹³å‡ç›ˆåˆ©æ”¶ç›Šç‡: {avg_win:.4%}")
    print(f"å¹³å‡äºæŸæ”¶ç›Šç‡: {avg_loss:.4%}")
    print(f"å®é™…ç›ˆäºæ¯”: {actual_profit_loss_ratio:.2f}")
    
    print(f"\n--- å‡¯åˆ©é¢„æœŸ vs å®é™…å¯¹æ¯” ---")
    print(f"å‡¯åˆ©é¢„æœŸèƒœç‡: {expected_win_rate:.2%}")
    print(f"å®é™…èƒœç‡: {win_rate:.2%}")
    print(f"å‡¯åˆ©é¢„æœŸç›ˆäºæ¯”: {expected_profit_loss_ratio:.2f}")
    print(f"å®é™…ç›ˆäºæ¯”: {actual_profit_loss_ratio:.2f}")
    
    # ä¸åŸºå‡†å¯¹æ¯”
    print(f"\n--- ä¸åŸºå‡†å¯¹æ¯” ---")
    print(f"V6åŸºå‡†æœŸæœ›æ”¶ç›Š: 1.57%")
    print(f"V24å‡¯åˆ©æœŸæœ›æ”¶ç›Š: {avg_return:.4%}")
    
    if avg_return >= 0.02:
        print("âœ… æœŸæœ›æ”¶ç›Šè¾¾åˆ°2%ç›®æ ‡ï¼")
    elif avg_return > 0.0157:
        print("âœ… æœŸæœ›æ”¶ç›Šè¶…è¶ŠV6åŸºå‡†ï¼")
    else:
        print("âŒ æœŸæœ›æ”¶ç›Šæœªè¶…è¶ŠV6åŸºå‡†")
    
    print(f"\näº¤æ˜“è®°å½•å·²ä¿å­˜è‡³: '{OUTPUT_CSV_PATH}'")

# ==============================================================================
# ä¸»å‡½æ•°
# ==============================================================================
def main():
    # 1. åŠ è½½æ•°æ®
    all_data = load_and_preprocess_data(DATA_PATH)
    if all_data is None:
        return
        
    # 2. å¯»æ‰¾V6åŸºç¡€ä¿¡å·
    v6_signals = find_v6_base_signals(all_data)
    
    if not v6_signals:
        print("æœªæ‰¾åˆ°ä»»ä½•V6ä¿¡å·ï¼Œæ— æ³•è¿›è¡ŒV24ç­›é€‰ã€‚")
        return
    
    # 3. æå–V24ç‰¹å¾
    print("å¼€å§‹æå–V24ç‰¹å¾...")
    featured_signals = []
    
    for signal in v6_signals:
        features = extract_v24_features(signal['è‚¡ç¥¨æ•°æ®'], signal['æ•°æ®ç´¢å¼•'])
        if features:
            features.update({
                'æ—¥æœŸ': signal['æ—¥æœŸ'],
                'ä»£ç ': signal['ä»£ç '],
                'ä¹°å…¥ä»·æ ¼': signal['ä¹°å…¥ä»·æ ¼']
            })
            featured_signals.append(features)
    
    signals_df = pd.DataFrame(featured_signals)
    print(f"æˆåŠŸä¸º {len(signals_df)} ä¸ªä¿¡å·æå–ç‰¹å¾")
    
    if signals_df.empty:
        print("ç‰¹å¾æå–å¤±è´¥ï¼Œæ— æ³•è¿›è¡ŒV24ç­›é€‰ã€‚")
        return
    
    # 4. V24 AIè¯„åˆ†
    scored_signals = v24_ai_scoring(signals_df)
    
    # 5. å‡¯åˆ©ç­›é€‰å’Œä»“ä½åˆ†é…
    kelly_signals = assign_kelly_position(scored_signals)
    
    if kelly_signals.empty:
        print("å‡¯åˆ©ç­›é€‰åæ— æœ‰æ•ˆä¿¡å·ï¼Œæ— æ³•è¿›è¡Œå›æµ‹ã€‚")
        return
    
    # 6. æ‰§è¡ŒV24å‡¯åˆ©å›æµ‹ (ä½¿ç”¨ä¸­ç«‹ä»“ä½)
    trades_df = run_v24_kelly_backtest(all_data, kelly_signals, 'ä¸­ç«‹ä»“ä½')
    
    # 7. ä¿å­˜å’Œåˆ†æç»“æœ
    if not trades_df.empty:
        trades_df.sort_values(by='ä¹°å…¥æ—¥æœŸ', inplace=True)
        trades_df.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')
        analyze_v24_performance(trades_df, 'ä¸­ç«‹ä»“ä½')

if __name__ == '__main__':
    main()